{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Iterable \n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionLatentUpscalePipeline\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import av\n",
    "import av.stream\n",
    "import imageio.v3 as iio\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path.cwd() / \"data\"\n",
    "SD_VID_PATH = DATA / \"inter4k_222_sd.mp4\"\n",
    "HD_VID_PATH = DATA / \"inter4k_222_hd.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(container: av.ContainerFormat) -> dict:\n",
    "    video = container.streams.video[0]\n",
    "    return {\n",
    "        \"width\": video.width,\n",
    "        \"height\": video.height,\n",
    "        \"duration\": float(video.duration * video.time_base),\n",
    "        \"fps\": float(video.average_rate),\n",
    "        \"frames\": video.frames,\n",
    "        \"pixel_format\": video.format \n",
    "    }\n",
    "\n",
    "def get_output_stream(container: av.ContainerFormat, fps: int, width: int, height: int, pixel_format: str, **kwargs)  -> av.video.stream.VideoStream:\n",
    "    stream = container.add_stream(\"mpeg4\", rate = fps)\n",
    "    stream.width = width\n",
    "    stream.height = height\n",
    "\n",
    "    # TODO: take pixel format input from metadata\n",
    "    stream.pix_fmt = \"yuv420p\" \n",
    "    return stream\n",
    "\n",
    "def write_frame_to_stream(container: av.ContainerFormat, stream: av.video.stream.VideoStream, frame: Optional[NDArray] = None):\n",
    "    frame = av.VideoFrame.from_ndarray(frame, format = \"rgb24\") if frame is not None else None\n",
    "    for packet in stream.encode(frame):\n",
    "        container.mux(packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upscale_pipelines():\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "        \"CompVis/stable-diffusion-v1-4\", \n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors = True\n",
    "    ).to(\"cuda\")\n",
    "    pipeline.enable_sequential_cpu_offload()\n",
    "    pipeline.enable_attention_slicing()\n",
    "\n",
    "    upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(\n",
    "        \"stabilityai/sd-x2-latent-upscaler\",\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "    upscaler.enable_sequential_cpu_offload()\n",
    "    upscaler.enable_attention_slicing()\n",
    "\n",
    "def get_upscaled_frame(frame: NDArray, prompt: str, generator: torch.Generator, sd_encoder: StableDiffusionPipeline, upscaler: StableDiffusionLatentUpscalePipeline):\n",
    "    low_res_latents = sd_encoder(\n",
    "        prompt = prompt,\n",
    "        image = frame,\n",
    "        generator = generator,\n",
    "        output_type = \"latent\",\n",
    "    ).images\n",
    "    upscaled_frame = upscaler(\n",
    "        prompt = prompt,\n",
    "        image = low_res_latents,\n",
    "        num_inference_steps = 20,\n",
    "        guidance_scale = 0,\n",
    "        generator = generator,\n",
    "    ).images[0]\n",
    "    return upscaled_frame\n",
    "\n",
    "\n",
    "def upscale_video(src_vid: Path, tgt_vid: Path, prompt: str, random_seed: int, limit_frames: int):\n",
    "    src_container = av.open(src_vid, \"r\")\n",
    "    tgt_container = av.open(tgt_vid, \"w\")\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(random_seed)\n",
    "\n",
    "    with tgt_container:\n",
    "        with src_container:\n",
    "            src_container.streams.video[0].thread_type = \"AUTO\"\n",
    "            metadata = get_metadata(src_container)\n",
    "            tgt_stream = get_output_stream(tgt_container, **metadata)\n",
    "            sd_encoder, upscaler = get_upscale_pipelines()\n",
    "\n",
    "            for i, src_frame in enumerate(src_container.decode(video = 0)):\n",
    "                if i > limit_frames:\n",
    "                    break\n",
    "\n",
    "                frame = src_frame.to_ndarray(format = \"rgb24\")\n",
    "                # frame = frame[120:360, 160:480, :].copy()\n",
    "                frame = get_upscaled_frame(frame, prompt, generator, sd_encoder, upscaler)\n",
    "                write_frame_to_stream(tgt_container, tgt_stream, frame)\n",
    "        write_frame_to_stream(tgt_container, tgt_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_video(SD_VID_PATH, HD_VID_PATH, \"nightscape\", 42, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Loaded video {SD_VID_PATH} as ndarray\")\n",
    "# print(f\"It's a {sd_vid.shape[1]}x{sd_vid.shape[2]} video which is\", end = \" \")\n",
    "# print(f\"{sd_vid_metadata['duration']}s long, at {sd_vid_metadata['fps']}fps, thus totalling {sd_vid.shape[0]} frames\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
