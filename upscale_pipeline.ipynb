{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from diffusers import (\n",
    "    StableDiffusionLatentUpscalePipeline\n",
    ")\n",
    "from torchvision.transforms.v2 import ToImage, ToDtype, Compose\n",
    "import imageio.v3 as iio\n",
    "\n",
    "from diffusers.utils.logging import disable_progress_bar\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path.cwd() / \"data\"\n",
    "SD_VID_PATH = DATA / \"inter4k_222_sd.mp4\"\n",
    "HD_VID_PATH = DATA / \"inter4k_222_hd.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upscale_pipelines():\n",
    "    upscaler_model_id = \"stabilityai/sd-x2-latent-upscaler\"\n",
    "    upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(\n",
    "        upscaler_model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors = True\n",
    "    )\n",
    "    #upscaler.scheduler = DDIMScheduler.from_config(\n",
    "        #upscaler.scheduler.config, timestep_spacing='trailing', rescale_betas_zero_snr=True,\n",
    "    #) pipeline.set_progress_bar_config(disable=True)\n",
    "    upscaler.set_progress_bar_config(disable = True)\n",
    "    upscaler = upscaler.to(\"cuda\")\n",
    "    #upscaler.enable_sequential_cpu_offload()\n",
    "    return upscaler\n",
    "\n",
    "def get_upscaled_frame(frame: NDArray, generator: torch.Generator, upscaler: StableDiffusionLatentUpscalePipeline):\n",
    "    return upscaler(\n",
    "        prompt = \" \",\n",
    "        image = frame,\n",
    "        num_inference_steps = 20,\n",
    "        guidance_scale = 0,\n",
    "        generator = generator,\n",
    "        output_type = \"pt\"\n",
    "    ).images[0].cpu()\n",
    "\n",
    "def upscale_video(src_vid: Path, tgt_vid: Path, random_seed: int, limit_frames: Optional[int] = None):\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(random_seed)\n",
    "    to_uint8 = Compose([ToImage(), ToDtype(torch.uint8, scale = True)]) \n",
    "    to_float32 = Compose([ToImage(), ToDtype(torch.float32, scale = True)]) \n",
    "\n",
    "    with iio.imopen(tgt_vid, \"w\", plugin = \"pyav\") as upscaled_vid:\n",
    "        metadata = iio.immeta(src_vid, plugin = \"pyav\")\n",
    "        if limit_frames is None:\n",
    "            limit_frames = metadata[\"fps\"] * metadata[\"duration\"]\n",
    "\n",
    "        upscaled_vid.init_video_stream(\"h264\", fps = metadata[\"fps\"])\n",
    "        upscaler = get_upscale_pipelines()\n",
    "\n",
    "        for i, frame in tqdm(enumerate(iio.imiter(src_vid, plugin = \"pyav\")), total = limit_frames):\n",
    "            if i >= limit_frames:\n",
    "                break\n",
    "            \n",
    "            # print(frame.shape, frame.dtype, frame.min().item(), frame.max().item())\n",
    "            low_res_frame = to_float32(frame)\n",
    "            # print(low_res_frame.shape, low_res_frame.dtype, low_res_frame.min().item(), low_res_frame.max().item())\n",
    "            high_res_frame = get_upscaled_frame(low_res_frame, generator, upscaler)\n",
    "            # print(high_res_frame.shape, high_res_frame.dtype, high_res_frame.min(), high_res_frame.max())\n",
    "            high_res_frame = to_uint8(high_res_frame).numpy()\n",
    "            # print(high_res_frame.shape, high_res_frame.dtype, high_res_frame.min(), high_res_frame.max())\n",
    "            upscaled_vid.write_frame(high_res_frame.transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300.0 [05:40<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "upscale_video(SD_VID_PATH, HD_VID_PATH, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_format': 'yuv420p',\n",
       " 'codec': 'h264',\n",
       " 'long_codec': 'H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10',\n",
       " 'profile': 'High',\n",
       " 'fps': 60.0,\n",
       " 'duration': 5.0,\n",
       " 'major_brand': 'isom',\n",
       " 'minor_version': '512',\n",
       " 'compatible_brands': 'isomiso2avc1mp41',\n",
       " 'encoder': 'Lavf60.16.100',\n",
       " 'language': 'und',\n",
       " 'handler_name': 'VideoHandler',\n",
       " 'vendor_id': '[0][0][0][0]'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iio.immeta(HD_VID_PATH, plugin = \"pyav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Loaded video {SD_VID_PATH} as ndarray\")\n",
    "# print(f\"It's a {sd_vid.shape[1]}x{sd_vid.shape[2]} video which is\", end = \" \")\n",
    "# print(f\"{sd_vid_metadata['duration']}s long, at {sd_vid_metadata['fps']}fps, thus totalling {sd_vid.shape[0]} frames\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
